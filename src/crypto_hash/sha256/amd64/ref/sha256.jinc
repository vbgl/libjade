
require "sha256_globals.jinc"

inline fn __initH_ref() -> stack u32[8]
{
  stack u32[8] H;

  H[0]  = 0x6a09e667;
  H[1]  = 0xbb67ae85;
  H[2]  = 0x3c6ef372;
  H[3]  = 0xa54ff53a;
  H[4]  = 0x510e527f;
  H[5]  = 0x9b05688c;
  H[6]  = 0x1f83d9ab;
  H[7]  = 0x5be0cd19;

  return H;
}

inline fn __load_H_ref(reg ptr u32[8] H) -> reg u32, reg u32, reg u32, reg u32,
                                            reg u32, reg u32, reg u32, reg u32,
                                            reg ptr u32[8]
{
  reg u32 a b c d e f g h;

  a = H[0];
  b = H[1];
  c = H[2];
  d = H[3];
  e = H[4];
  f = H[5];
  g = H[6];
  h = H[7];

  return a, b, c, d, e, f, g, h, H;
}

inline fn __store_H_ref(reg ptr u32[8] H, reg u32 a b c d e f g h) -> reg ptr u32[8]
{
  H[0] = a;
  H[1] = b;
  H[2] = c;
  H[3] = d;
  H[4] = e;
  H[5] = f;
  H[6] = g;
  H[7] = h;

  return H;
}

inline fn __store_ref(reg u64 out, stack u32[8] H)
{
  inline int i;
  reg u32 v;

  for i=0 to 8
  { v = H[i];
    v = #BSWAP_32(v);
    (u32)[out + i*4] = v;
  }
}

inline fn __SHR_ref(reg u32 x, inline int c) -> reg u32
{
  reg u32 r;
  r   = x;
  r >>= c;
  return r;
}

inline fn __ROTR_ref(reg u32 x, inline int c) -> reg u32
{
  reg u32 r;
  r = x;
  _, _, r = #ROR_32(r, c);
  return r;
}

//(x & y) ^ (!x & z)
inline fn __CH_ref(reg u32 x y z) -> reg u32
{
  reg u32 r s;

  r  =  x;
  r &=  y;
  s  =  x;
  s  = !s;
  s &=  z;
  r ^=  s;

  return r;
}

//(x & y) ^ (x & z) ^ (y & z)
inline fn __MAJ_ref(reg u32 x y z) -> reg u32
{
  reg u32 r s;

  r  = x;
  r &= y;
  s  = x;
  s &= z;
  r ^= s;
  s  = y;
  s &= z;
  r ^= s;

  return r;
}

// (x >>> 2) ^ (x >>> 13) ^ (x >>> 22)
inline fn __BSIG0_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 2);
  s  = __ROTR_ref(x,13);
  r ^= s;
  s  = __ROTR_ref(x,22);
  r ^= s;

  return r;
}

// (x >>> 6) ^ (x >>> 11) ^ (x >>> 25)
inline fn __BSIG1_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 6);
  s  = __ROTR_ref(x,11);
  r ^= s;
  s  = __ROTR_ref(x,25);
  r ^= s;

  return r;
}

// (x >>> 7) ^ (x >>> 18) ^ (x >> 3)
inline fn __SSIG0_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 7);
  s  = __ROTR_ref(x,18);
  r ^= s;
  s  = __SHR_ref(x,3);
  r ^= s;

  return r;
}

// (x >>> 17) ^ (x >>> 19) ^ (x >> 10)
inline fn __SSIG1_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x,17);
  s  = __ROTR_ref(x,19);
  r ^= s;
  s  = __SHR_ref(x,10);
  r ^= s;

  return r;
}

// Wt = SSIG1(W(t-2)) + W(t-7) + SSIG0(t-15) + W(t-16)
inline fn __Wt_ref(stack u32[64] W, inline int t) -> stack u32[64]
{
  reg u32 wt wt2 wt15;

  wt2  = W[t-2];
  wt   = __SSIG1_ref(wt2);
  wt  += W[t-7];
  wt15 = W[t-15];
  wt15 = __SSIG0_ref(wt15);
  wt  += wt15;
  wt  += W[t-16];

  W[t] = wt;

  return W;
}

fn _blocks_0_ref(reg ptr u32[8] _H, reg u64 in inlen, #msf reg u64 ms) -> reg ptr u32[8], reg u64, reg u64, #msf reg u64
{
  inline int t, i;
  reg u32 T1 T2 a b c d e f g h r v;
  stack u32[64] W;
  reg ptr u32[64] Kp;
  stack ptr u32[8] Hp;
  reg ptr u32[8] H;
  stack u64 in_s;
  reg bool b1;

  Kp = SHA256_K;
  Hp = _H;

  H = Hp;
  while { b1 = inlen >= 64; } (b1)
  {
    ms = #set_msf(b1, ms);
    for t=0 to 16
    { v = (u32)[in + t*4];
      v = #BSWAP_32(v);
      W[t] = v;
    }
    in_s = in;

    for t=16 to 64
    { W = __Wt_ref(W, t); }

    a, b, c, d, e, f, g, h, H = __load_H_ref(H);
    Hp = H;

    for i = 0 to 64
    {
      //T1 = h + BSIG1(e) + CH(e,f,g) + Kt + Wt
      T1  = h;
      r   = __BSIG1_ref(e);
      T1 += r;
      r   = __CH_ref(e,f,g);
      T1 += r;
      T1 += Kp[i];
      T1 += W[i];

      //T2 = BSIG0(a) + MAJ(a,b,c)
      T2  = __BSIG0_ref(a);
      r   = __MAJ_ref(a,b,c);
      T2 += r;

      h  = g;
      g  = f;
      f  = e;
      e  = d;
      e += T1;
      d  = c;
      c  = b;
      b  = a;
      a  = T1;
      a += T2;
    }

    H = Hp;
    a += H[0];
    b += H[1];
    c += H[2];
    d += H[3];
    e += H[4];
    f += H[5];
    g += H[6];
    h += H[7];

    H = __store_H_ref(H,a,b,c,d,e,f,g,h);
    //Hp = H;

    in = in_s;
    in = #protect(in, ms);
    in += 64;
    inlen -= 64;
    inlen = #protect(inlen, ms);
  }
  ms = #set_msf(!b1, ms);

  _H = H;
  return _H, in, inlen, ms;
}

fn _blocks_1_ref(reg ptr u32[8] _H, reg ptr u32[32] sblocks, reg u64 nblocks, #msf reg u64 ms) -> reg ptr u32[8], reg ptr u32[32], #msf reg u64
{
  inline int t i;
  reg u32 T1 T2 a b c d e f g h r v;
  stack u32[64] W;
  reg ptr u32[64] Kp;
  stack ptr u32[8] Hp;
  reg ptr u32[8] H;
  stack ptr u32[32] s_sblocks;
  reg u64 oblocks;
  stack u64 s_oblocks;
  reg bool b1;

  Kp = SHA256_K;
  Hp = _H;
  oblocks = 0;

  H = Hp;

  while { b1 = nblocks > 0; } (b1)
  {
    ms = #set_msf(b1, ms);
    for t=0 to 16
    { v = sblocks[(int)oblocks + t];
      v = #BSWAP_32(v);
      W[t] = v;
    }
    oblocks += 16;
    s_oblocks = oblocks;
    s_sblocks = sblocks;

    for t=16 to 64
    { W = __Wt_ref(W, t); }

    a, b, c, d, e, f, g, h, H = __load_H_ref(H);
    Hp = H;

    for i = 0 to 64
    {
      //T1 = h + BSIG1(e) + CH(e,f,g) + Kt + Wt
      T1  = h;
      r   = __BSIG1_ref(e);
      T1 += r;
      r   = __CH_ref(e,f,g);
      T1 += r;
      T1 += Kp[i];
      T1 += W[i];

      //T2 = BSIG0(a) + MAJ(a,b,c)
      T2  = __BSIG0_ref(a);
      r   = __MAJ_ref(a,b,c);
      T2 += r;

      h  = g;
      g  = f;
      f  = e;
      e  = d;
      e += T1;
      d  = c;
      c  = b;
      b  = a;
      a  = T1;
      a += T2;
    }

    H = Hp;
    a += H[0];
    b += H[1];
    c += H[2];
    d += H[3];
    e += H[4];
    f += H[5];
    g += H[6];
    h += H[7];

    H = __store_H_ref(H,a,b,c,d,e,f,g,h);

    sblocks = s_sblocks;
    sblocks = #protect_ptr(sblocks, ms);
    oblocks = s_oblocks;
    oblocks = #protect(oblocks, ms);
    nblocks -= 1;
  }
  ms = #set_msf(!b1, ms);

  _H = H;
  return _H, sblocks, ms;
}


inline fn __lastblocks_ref(reg u64 in inlen bits, #msf reg u64 ms) -> stack u32[32], reg u64, #msf reg u64
{
  stack u32[32] sblocks;
  reg u64 i j nblocks;
  reg u8 v;
  reg bool b;

  // copy in to sblocks
  i = 0;
  while { b = i < inlen; } (b)
  {
    ms = #set_msf(b, ms);
    v = (u8)[in + i];
    sblocks[u8 (int)i] = v;
    i += 1;
  }
  ms = #set_msf(!b, ms);

  // set first byte after input to 0x80
  sblocks[u8 (int)i] = 0x80;
  i += 1;

  // check if one or two blocks are needed
  b = inlen < 56;
  if(b)
  { ms = #set_msf(b, ms); j = (64-8); nblocks = 1; }
  else
  { ms = #set_msf(!b, ms); j = (128-8); nblocks = 2; }

  // set remaining bytes to zero (can be optimized)
  v = 0;
  while {b = i < j; } (b)
  {
    ms = #set_msf(b, ms);
    sblocks[u8 (int)i] = v;
    i += 1;
  }
  ms = #set_msf(!b, ms);
  i += 7; // i=63 || i=127

  while{ b = i >= j; } (b)
  {
    ms = #set_msf(b, ms);
    sblocks[u8 (int)i] = (8u) bits;
    bits >>= 8;
    i -= 1;
  }
  ms = #set_msf(!b, ms);
  i += 9;

  // set remaining bytes to zero (can be optimized)
  while{ b= i < 128; } (b)
  {
    ms = #set_msf(b, ms);
    sblocks[u8 (int)i] = v;
    i += 1;
  }
  ms = #set_msf(!b, ms);

  return sblocks, nblocks, ms;
}

inline fn __sha256(reg u64 out in inlen ms)
{
  reg u64 bits nblocks;
  stack u64 s_out s_bits;
  stack u32[8] H;
  reg ptr u32[8] Hp;
  stack u32[32] sblocks;
  reg ptr u32[32] sblocksp;

  s_out = out;

  bits = inlen;
  bits <<= 3;
  s_bits = bits;

  H = __initH_ref();
  Hp = H;
  Hp, in, inlen, ms = _blocks_0_ref(Hp, in, inlen, ms);

  bits = s_bits;
  sblocks, nblocks, ms = __lastblocks_ref(in, inlen, bits, ms);
  sblocksp = sblocks;
  Hp, _ , ms = _blocks_1_ref(Hp, sblocksp, nblocks, ms);

  out = s_out;
  out = #protect(out, ms);
  H = Hp;
  __store_ref(out, H);
}
